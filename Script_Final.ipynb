{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE PROJECT: Start with an input text and provide a schema that summarises the process described in the text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATION PART (STEP 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to take an action list and turn it into a complete visualisation. To achieve this, we first had to define the type of object that the NLP part would provide. We started with a dictionary where the keys represent the actions and the values represent all the actions that preceded each key action. An example is provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple = {\n",
    "    'A': [],\n",
    "    'B': ['A'],\n",
    "    'C': ['A'],\n",
    "    'D': ['B', 'C', 'A'],\n",
    "    'E': ['B','A'],\n",
    "    'F': ['D','A','C','B'],\n",
    "    'G': ['B','A','C','E', 'F']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second challenge is to start from this input and succeed in defining the tasks that immediately precede each of the tasks. This is what we call the immediate antecedent. \n",
    "To do this, we used the PERT (Program Evaluation and Review Technique) method of scheduling tasks in graph theory. It is particularly effective when there are multiple dependencies between tasks.\n",
    "\n",
    "To arrive at a more or less correct representation, this method requires the prior determination of the rank of the tasks, which facilitates the determination of the immediate antecedents.\n",
    "The rank of a task corresponds to its position in the logical sequence of tasks. More precisely, the rank of a task is determined by the highest value among the ranks of all the tasks that directly precede it.\n",
    "The starting rank is generally 0, since the first task does not precede any other task.\n",
    "\n",
    "**Principle**\n",
    "\n",
    "We look for tasks that have no antecedents, and assign them rank 0. We then remove these tasks from the list of antecedents of the other tasks. Once this is done, the tasks that have no antecedents are assigned rank 1, and so on.\n",
    "\n",
    "This is what the function \"niveau\" below does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def niveau(previou): #Returns the rank of each task # Small warning, the function modifies the initial dict, so take care to send it only one copy\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    previous=copy.deepcopy(previou)\n",
    "    \n",
    "    # \n",
    "    def retrait (list_a, list_b) : \n",
    "        for i in list_b:\n",
    "            while i in list_a:\n",
    "                list_a.remove(i)\n",
    "        return list_a\n",
    "\n",
    "    def condition(dictionnaire): \n",
    "        a=False\n",
    "        for j in dictionnaire:\n",
    "            if len(dictionnaire[j])!=0:\n",
    "                a=True\n",
    "        return a        \n",
    "\n",
    "    #Dictionary to store ranks\n",
    "    rang={}\n",
    "    for j in previous:\n",
    "        rang[j]=0\n",
    "\n",
    "    #Loop for browsing items\n",
    "    i=1\n",
    "    noeud_modifie=[]\n",
    "    while(condition(previous)):\n",
    "        \n",
    "        sommet=[]\n",
    "        \n",
    "        for j in previous: #Find nodes that have no antecedents and assign them a rank\n",
    "            if (len(previous[j])==0) & (not(j in noeud_modifie)) : \n",
    "                rang[j]+=i\n",
    "                sommet.append(j)\n",
    "\n",
    "        for j in previous: #Removing nodes without antecedents from the antecedents list\n",
    "            previous[j]=retrait(previous[j], sommet)\n",
    "        \n",
    "        noeud_modifie.extend(sommet)\n",
    "        i+=1\n",
    "\n",
    "    ## A final process to take account of the last node not processed in the loop\n",
    "    for j in rang:\n",
    "        if rang[j]==0 : \n",
    "            rang[j]=i\n",
    "    \n",
    "    \n",
    "    return(rang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 1, 'B': 2, 'C': 2, 'D': 3, 'E': 3, 'F': 4, 'G': 5}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "niveau(exemple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the ranks are known, the immediate antecedents of each task can be extracted (see below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ant_immediat(previous):\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    #\n",
    "    def complement(list_a, list_b) : # \n",
    "        return(list(set(list_a)-set(list_b)))\n",
    "    \n",
    "    def ant_rang(x, n) : #List of all nodes of a given rank\n",
    "        rang=niveau(x)\n",
    "        antec=[]\n",
    "        for e in rang:\n",
    "            if rang[e]==n:\n",
    "                antec.append(e)\n",
    "        return antec\n",
    "    \n",
    "    #Implementation\n",
    "    rang=niveau(previous)\n",
    "    \n",
    "    noeud_a_modifie=[]\n",
    "    for j in rang:\n",
    "        if rang[j]!=1:\n",
    "            noeud_a_modifie.append(j)\n",
    "    \n",
    "    prev=copy.deepcopy(previous)\n",
    "    \n",
    "    for i in noeud_a_modifie:\n",
    "        antec=ant_rang(previous,rang[i]-1)\n",
    "        prev[i]=list(set(prev[i])-set(complement(prev[i],antec)))\n",
    "        \n",
    "    for i in  noeud_a_modifie:\n",
    "        for j in range(rang[i]-1,1,-1):\n",
    "            antec=list(set(ant_rang(previous,j))&set(previous[i]))\n",
    "            antec2=copy.deepcopy(antec)\n",
    "            for e in antec:\n",
    "                v=False\n",
    "                for u in prev[i]:\n",
    "                    if e in previous[u] : v=True\n",
    "                if v : antec2.remove(e)\n",
    "            prev[i].extend(antec2)  \n",
    "    \n",
    "    for i in prev : \n",
    "        prev[i]=list(set(prev[i]))\n",
    "      \n",
    "    return prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [],\n",
       " 'B': ['A'],\n",
       " 'C': ['A'],\n",
       " 'D': ['C', 'B'],\n",
       " 'E': ['B'],\n",
       " 'F': ['D'],\n",
       " 'G': ['F', 'E']}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ant_immediat(exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "From the antecedents we can then construct the graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.4 (20230422.2207)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 134.00 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-328 130,-328 130,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-300.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-228.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.35,-288.76C75.62,-280.46 80.92,-270.15 85.73,-260.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.23,-262.64 90.7,-252.15 83.01,-259.44 89.23,-262.64\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-228.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;C -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>A&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.65,-288.76C50.38,-280.46 45.08,-270.15 40.27,-260.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"42.99,-259.44 35.3,-252.15 36.77,-262.64 42.99,-259.44\"/>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-156.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;D -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>B&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.08,-218.5C74.14,-208.83 60.88,-195.94 49.65,-185.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.51,-182.95 42.9,-178.49 47.63,-187.97 52.51,-182.95\"/>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">E</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;E -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>B&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-215.59C99,-191.5 99,-147.75 99,-119.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-119.11 99,-109.11 95.5,-119.11 102.5,-119.11\"/>\n",
       "</g>\n",
       "<!-- C&#45;&gt;D -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>C&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-215.7C27,-208.24 27,-199.32 27,-190.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-191.1 27,-181.1 23.5,-191.1 30.5,-191.1\"/>\n",
       "</g>\n",
       "<!-- F -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>F</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;F -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>D&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-143.7C27,-136.24 27,-127.32 27,-118.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-119.1 27,-109.1 23.5,-119.1 30.5,-119.1\"/>\n",
       "</g>\n",
       "<!-- G -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>G</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">G</text>\n",
       "</g>\n",
       "<!-- E&#45;&gt;G -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>E&#45;&gt;G</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.38,-64.46 81.08,-54.15 76.27,-44.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-43.44 71.3,-36.15 72.77,-46.64 78.99,-43.44\"/>\n",
       "</g>\n",
       "<!-- F&#45;&gt;G -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>F&#45;&gt;G</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.62,-64.46 44.92,-54.15 49.73,-44.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-46.64 54.7,-36.15 47.01,-43.44 53.23,-46.64\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x166638e2dc0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import graphviz  \n",
    "diag=graphviz.Digraph()\n",
    "\n",
    "immediat=ant_immediat(exemple)\n",
    "\n",
    "    \n",
    "for i in immediat :\n",
    "    diag.node(i)  \n",
    "    \n",
    "sens=[]\n",
    "\n",
    "for i in immediat :\n",
    "    for j in immediat[i]:\n",
    "        diag.edge(j, i)\n",
    "        \n",
    "#Display\n",
    "diag\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP PART (STEP 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the visualisation part is in place, we now want to start with a text and provide the input required for visualisation: a list of actions and their antecedents.\n",
    "We proceed by syntactic analysis. We assume that an action is composed mainly of a verb. To support the description of the action, we look at the complements of the verb to see if they can be added to specify the action.  The different categories of complements are treated differently: proper and common nouns are simply added to the description of the action, adjectives are added with the verb that follows them, and adverbs are added with the verb that precedes them. Additions that are punctuation or determiners are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Load the spaCy French language model\n",
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_action ( texte ) : # Take a text as input and extract a chronological list of actions. The text must follow a certain structure as explained in the document.\n",
    "    # Syntactic analysis: Action = Verb which is either ROOT, or Conjoint or Xcomp. To this verb, we add its complements if they improve the description of the action.\n",
    "    \n",
    "    doc = nlp(texte)\n",
    "    \n",
    "    actions = [] # Initialising the list of actions\n",
    "    \n",
    "    for sent in doc.sents: # \n",
    "        \n",
    "        action_found = False #\n",
    "        \n",
    "        for token in sent: #To browse the tokens in the sentence. If the token is a verb and is the root of the sentence, or is conjoined or xcomp, then it is considered to be an action\n",
    "            \n",
    "            if token.pos_ == \"VERB\" and (token.dep_ == \"ROOT\" or token.dep_ == \"conj\" or token.dep_ == \"xcomp\"):\n",
    "                \n",
    "                action = token.text # Retrieving verb text\n",
    "                \n",
    "                compléments = [child for child in token.children if child.pos_ != \"PUNCT\" and child.pos_ != \"DET\"] # Retrieving verb complements (all those that are neither punctuation nor a determiner)\n",
    "                compléments_texte = [child.text for child in compléments] # Retrieving complements text\n",
    "                \n",
    "                for comp in compléments: # Browse the complements and analyse them on a case-by-case basis\n",
    "                    \n",
    "                    if comp.pos_ == \"PROPN\":  # If the complement is a proper noun, it is added to the list of actions\n",
    "                        actions.append(action + \" \" + comp.text)\n",
    "                        action_found = True\n",
    "                        break\n",
    "                    \n",
    "                    elif comp.pos_ == \"NOUN\": # If the complement is a common noun, it is added to the list of actions\n",
    "                        actions.append(action + \" \" + comp.text)\n",
    "                        action_found = True\n",
    "                        break\n",
    "                    \n",
    "                    elif comp.pos_ == \"ADJ\": # If the complement is an adjective, we add the verb, the adjective and the text of the verb to the list of actions.\n",
    "                        actions.append(action + \" \" + comp.text + \" \" + token.text)\n",
    "                        action_found = True\n",
    "                        break\n",
    "                    \n",
    "                    elif comp.pos_ == \"ADV\": # If the complement is an adverb, we add the adverb and the verb to the list of actions\n",
    "                        actions.append(comp.text + \" \" + action)\n",
    "                        action_found = True\n",
    "                        break\n",
    "                    \n",
    "            if action_found: # If an action has been found for the current phrase, the search is stopped.\n",
    "                break\n",
    "            \n",
    "    return(actions)  # \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have this list of actions, we put them in the right format for the visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_format (liste_action) : #Takes as input a list of actions and returns a dictionary where each action in the list is associated with a list of all the actions that follow it chronologically\n",
    "    \n",
    "    sortie=[] # # \n",
    "    for i in liste_action: \n",
    "        sortie.append([])\n",
    "        \n",
    "    for i in range(len(liste_action)): # \n",
    "        for j in range(i+1,len(liste_action)):\n",
    "            sortie [j].append(liste_action[i]) #\n",
    "            \n",
    "    sorti=dict(zip(liste_action,sortie)) # \n",
    "    return(sorti)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final part\n",
    "From all the above, we define a final function that performs all the desired processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(texte) : \n",
    "    \n",
    "    import copy\n",
    "    import graphviz  # doctest: +NO_EXE\n",
    "    diag=graphviz.Digraph()\n",
    "\n",
    "    immediat=ant_immediat(conversion_format(extraction_action(texte)))\n",
    "\n",
    "    \n",
    "    for i in immediat :\n",
    "        diag.node(i)  \n",
    "    \n",
    "    sens=[]\n",
    "\n",
    "    for i in immediat :\n",
    "        for j in immediat[i]:\n",
    "            diag.edge(j, i)\n",
    "\n",
    "    #Display\n",
    "    return(diag)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to process\n",
    "texte = \"Pour préparer le riz, il faut d'abord le rincer plusieurs fois à l'eau froide. Ensuite, verser le riz dans une casserole avec de l'eau froide et porter à ébullition. Réduire le feu et couvrir la casserole. Laisser cuire pendant environ 18 minutes. Enfin, retirer la casserole du feu et laisser reposer le riz pendant 5 minutes avant de servir.\"\n",
    "texte2 =\"La préparation du pain nécessite plusieurs étapes essentielles. Tout d'abord, il faut rassembler les ingrédients nécessaires tels que la farine, le sel, la levure et l'eau. Ensuite, on mélange ces ingrédients dans un grand bol et on pétrit la pâte pendant plusieurs minutes jusqu'à ce qu'elle soit bien lisse et homogène. Ensuite, on laisse reposer la pâte pendant quelques heures dans un endroit chaud pour qu'elle puisse lever. Une fois que la pâte a doublé de volume, on la pétrit à nouveau pour la dégazer et on la façonne en boule. Enfin, on met la boule de pâte dans un moule à pain et on la laisse cuire au four pendant environ une heure, jusqu'à ce que la croûte soit dorée et croustillante. Et voilà, le pain est prêt à être dégusté !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.4 (20230422.2207)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"181pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 180.99 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-328 176.99,-328 176.99,4 -4,4\"/>\n",
       "<!-- rincer fois -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>rincer fois</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86.49\" cy=\"-306\" rx=\"48.07\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.49\" y=\"-300.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">rincer fois</text>\n",
       "</g>\n",
       "<!-- Ensuite verser -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Ensuite verser</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86.49\" cy=\"-234\" rx=\"62.54\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.49\" y=\"-228.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Ensuite verser</text>\n",
       "</g>\n",
       "<!-- rincer fois&#45;&gt;Ensuite verser -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>rincer fois&#45;&gt;Ensuite verser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.49,-287.7C86.49,-280.24 86.49,-271.32 86.49,-262.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.99,-263.1 86.49,-253.1 82.99,-263.1 89.99,-263.1\"/>\n",
       "</g>\n",
       "<!-- couvrir casserole -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>couvrir casserole</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86.49\" cy=\"-162\" rx=\"74.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.49\" y=\"-156.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">couvrir casserole</text>\n",
       "</g>\n",
       "<!-- Ensuite verser&#45;&gt;couvrir casserole -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Ensuite verser&#45;&gt;couvrir casserole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.49,-215.7C86.49,-208.24 86.49,-199.32 86.49,-190.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.99,-191.1 86.49,-181.1 82.99,-191.1 89.99,-191.1\"/>\n",
       "</g>\n",
       "<!-- Laisser cuire Laisser -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Laisser cuire Laisser</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86.49\" cy=\"-90\" rx=\"86.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.49\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Laisser cuire Laisser</text>\n",
       "</g>\n",
       "<!-- couvrir casserole&#45;&gt;Laisser cuire Laisser -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>couvrir casserole&#45;&gt;Laisser cuire Laisser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.49,-143.7C86.49,-136.24 86.49,-127.32 86.49,-118.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.99,-119.1 86.49,-109.1 82.99,-119.1 89.99,-119.1\"/>\n",
       "</g>\n",
       "<!-- Enfin retirer -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Enfin retirer</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86.49\" cy=\"-18\" rx=\"54.06\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.49\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Enfin retirer</text>\n",
       "</g>\n",
       "<!-- Laisser cuire Laisser&#45;&gt;Enfin retirer -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Laisser cuire Laisser&#45;&gt;Enfin retirer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.49,-71.7C86.49,-64.24 86.49,-55.32 86.49,-46.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.99,-47.1 86.49,-37.1 82.99,-47.1 89.99,-47.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x166638e2e80>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image(texte)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMITATIONS\n",
    "\n",
    "Since the NLP part is based solely on syntactic analysis, the ability to extract actions is limited. To be properly understood, the text must respect certain specificities:\n",
    "- each action must be described in a single sentence\n",
    "- The succession of sentences marks the chronology of actions.\n",
    "\n",
    "Apart from this, syntactic analysis does not take into account conditional structures and complex dependencies between actions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
